# -*- coding: utf-8 -*-
"""Untitled2_modified.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14ue33TF8metot6RzQivSOztoLUCp1NgK
"""

# Cell 1: Install required packages
!pip install fastapi uvicorn python-multipart
!pip install transformers torch torchvision pillow
!pip install requests numpy
!pip install pyngrok
!pip install python-jose[cryptography]

pip install pyngrok

# ================================
# Cell 2: Import libraries and setup
# ================================
import os
import io
import base64
import random
import requests
from PIL import Image
import torch
from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer
from fastapi import FastAPI, File, UploadFile, Form, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn
from pyngrok import ngrok
import asyncio
from typing import Optional

# Set up the device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Initialize FastAPI app
app = FastAPI(title="AI Caption Generator", description="Generate cool Instagram-style captions")

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ================================
# Cell 3: Load the pre-trained ViT-GPT2 model
# ================================
print("Loading ViT-GPT2 image captioning model...")
model_name = "nlpconnect/vit-gpt2-image-captioning"
processor = ViTImageProcessor.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = VisionEncoderDecoderModel.from_pretrained(model_name).to(device)
print("Model loaded successfully!")

# ================================
# Cell 4: Caption generation functions
# ================================

def enhance_caption_with_style(base_caption: str, vibe: str, user_description: str = ""):
    """
    Turn a plain descriptive caption into a stylish Instagram-like caption
    with emotion, vibe-based wording, and natural emoji use.
    """

    # Define vibe themes & emojis
    vibe_styles = {
        "happy": {
            "templates": [
                "Sunshine vibes all the way ☀️💛",
                "Pure joy in every pixel ✨🌈",
                "Smiles as bright as the day 🌟😊",
                "Happiness overload 💕🌸"
            ],
            "emojis": ["😊", "✨", "🌈", "💛", "🌸", "🌟"]
        },
        "sad": {
            "templates": [
                "Quiet moments in a noisy world 🌧️💙",
                "Raindrops match my mood 🌧️🌿",
                "Soft shades of a heavy heart 💭💔",
                "Sometimes beauty is in the melancholy 🌙💧"
            ],
            "emojis": ["💙", "🌧️", "🌙", "💧", "💭", "🍂"]
        },
        "adventurous": {
            "templates": [
                "Chasing horizons 🌍✨",
                "Adventure is calling, I must go 🏞️🚀",
                "Collecting moments, not things 📍🌄",
                "Lost in the right direction 🧭🌿"
            ],
            "emojis": ["🌍", "🏞️", "🚀", "🌄", "🧭", "🌿"]
        },
        "romantic": {
            "templates": [
                "Love written in the skies 🌹💫",
                "Two souls, one heartbeat ❤️🌙",
                "Whispers of forever 💕🌸",
                "In your arms is home 🌹💍"
            ],
            "emojis": ["🌹", "💫", "❤️", "🌙", "💕", "💍"]
        },
        "mysterious": {
            "templates": [
                "Whispers in the shadows 🌌🖤",
                "Stories the moon will never tell 🌙✨",
                "Lost between reality and dreams 🌫️🔮",
                "Eyes full of secrets 🖤🌑"
            ],
            "emojis": ["🌌", "🖤", "🌙", "✨", "🔮", "🌑"]
        },
        "energetic": {
            "templates": [
                "Vibes louder than my playlist 🎶🔥",
                "Too much energy to stand still ⚡💥",
                "Life in full volume 🎧✨",
                "Powered by pure adrenaline 🚀🔥"
            ],
            "emojis": ["⚡", "🔥", "💥", "🎧", "✨", "🚀"]
        }
    }

    vibe_data = vibe_styles.get(vibe, vibe_styles["happy"])

    # Shorten base caption and extract keywords
    base_caption_clean = base_caption.strip().capitalize()
    keywords = base_caption_clean.split()[:5]  # top 5 words

    # Creative rephrasings using keywords
    keyword_phrase = " ".join(keywords)
    custom_templates = [
        f"{keyword_phrase} vibes {random.choice(vibe_data['emojis'])}",
        f"{random.choice(vibe_data['templates'])} — {keyword_phrase.lower()}",
        f"{keyword_phrase} but make it {vibe} {random.choice(vibe_data['emojis'])}",
        f"Just {keyword_phrase.lower()} things {random.choice(vibe_data['emojis'])}"
    ]

    # Merge templates
    all_templates = vibe_data["templates"] + custom_templates

    # If user provided extra description, weave it in
    if user_description:
        all_templates += [
            f"{random.choice(vibe_data['templates'])} • {user_description.lower()}",
            f"{user_description.capitalize()} & {keyword_phrase.lower()} {random.choice(vibe_data['emojis'])}"
        ]

    # Pick a stylish caption
    caption = random.choice(all_templates)

    return caption.strip()



def generate_enhanced_caption(image, vibe: str, user_description: str = ""):
    """Generate captions using ViT-GPT2 and style them."""
    image = process_image(image)
    pixel_values = processor(images=image, return_tensors="pt").pixel_values.to(device)

    with torch.no_grad():
        output_ids = model.generate(
            pixel_values,
            max_length=50,
            min_length=15,
            num_beams=5,
            temperature=0.8,
            repetition_penalty=1.2
        )
    base_caption = tokenizer.decode(output_ids[0], skip_special_tokens=True).strip()

    enhanced_caption = enhance_caption_with_style(base_caption, vibe, user_description)
    return enhanced_caption, base_caption


def process_image(image):
    """Ensure image is RGB and resized."""
    if image.mode != 'RGB':
        image = image.convert('RGB')
    max_size = 512
    if max(image.size) > max_size:
        image.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)
    return image

# ================================
# Cell 5: API endpoints
# ================================
class CaptionURLRequest(BaseModel):
    image_url: str
    vibe: str = "happy"
    user_description: str = ""

class RefreshCaptionRequest(BaseModel):
    base_caption: str
    vibe: str = "happy"
    user_description: str = ""

@app.post("/generate-caption-upload")
async def generate_caption_upload(
    file: UploadFile = File(...),
    vibe: str = Form("happy"),
    user_description: str = Form("")
):
    try:
        if not file.content_type.startswith('image/'):
            raise HTTPException(status_code=400, detail="File must be an image")

        contents = await file.read()
        image = Image.open(io.BytesIO(contents))

        cool_caption, base_caption = generate_enhanced_caption(image, vibe.lower(), user_description)

        return {
            "success": True,
            "caption": cool_caption,
            "base_caption": base_caption,
            "user_description": user_description,
            "vibe": vibe
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error generating caption: {str(e)}")


@app.post("/generate-caption-url")
async def generate_caption_url(body: CaptionURLRequest):
    try:
        response = requests.get(body.image_url, timeout=10)
        response.raise_for_status()
        image = Image.open(io.BytesIO(response.content))

        cool_caption, base_caption = generate_enhanced_caption(image, body.vibe.lower(), body.user_description)

        return {
            "success": True,
            "caption": cool_caption,
            "base_caption": base_caption,
            "user_description": body.user_description,
            "vibe": body.vibe
        }
    except requests.RequestException:
        raise HTTPException(status_code=400, detail="Could not download image from URL")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error generating caption: {str(e)}")


@app.post("/refresh-caption")
async def refresh_caption(body: RefreshCaptionRequest):
    try:
        cool_caption = enhance_caption_with_style(body.base_caption, body.vibe.lower(), body.user_description)
        return {
            "success": True,
            "caption": cool_caption,
            "base_caption": body.base_caption,
            "user_description": body.user_description,
            "vibe": body.vibe
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error refreshing caption: {str(e)}")


@app.get("/vibes")
async def get_available_vibes():
    return {
        "vibes": ["happy", "sad", "adventurous", "romantic", "mysterious", "energetic"]
    }

import nest_asyncio
import uvicorn

ngrok.set_auth_token("31AlJuXfCHs6opLvtXrEfp45qgE_5ddxVm5BMpRntk5Qf7eVJ")
public_url = ngrok.connect(8000)
print(f"🚀 Your API is now accessible at: {public_url}")
print(f"📋 Copy this URL for your frontend: {public_url}")

# Allow nested event loops/
nest_asyncio.apply()

# Run server directly
uvicorn.run(app, host="0.0.0.0", port=8000)

