# -*- coding: utf-8 -*-
"""Untitled2_modified.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14ue33TF8metot6RzQivSOztoLUCp1NgK
"""

# Cell 1: Install required packages
!pip install fastapi uvicorn python-multipart
!pip install transformers torch torchvision pillow
!pip install requests numpy
!pip install pyngrok
!pip install python-jose[cryptography]

pip install pyngrok

# ================================
# Cell 2: Import libraries and setup
# ================================
import os
import io
import base64
import random
import requests
from PIL import Image
import torch
from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer
from fastapi import FastAPI, File, UploadFile, Form, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn
from pyngrok import ngrok
import asyncio
from typing import Optional

# Set up the device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Initialize FastAPI app
app = FastAPI(title="AI Caption Generator", description="Generate cool Instagram-style captions")

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ================================
# Cell 3: Load the pre-trained ViT-GPT2 model
# ================================
print("Loading ViT-GPT2 image captioning model...")
model_name = "nlpconnect/vit-gpt2-image-captioning"
processor = ViTImageProcessor.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = VisionEncoderDecoderModel.from_pretrained(model_name).to(device)
print("Model loaded successfully!")

# ================================
# Cell 4: Caption generation functions
# ================================

def enhance_caption_with_style(base_caption: str, vibe: str, user_description: str = ""):
    """
    Turn a plain descriptive caption into a stylish Instagram-like caption
    with emotion, vibe-based wording, and natural emoji use.
    """

    # Define vibe themes & emojis
    vibe_styles = {
        "happy": {
            "templates": [
                "Sunshine vibes all the way â˜€ï¸ðŸ’›",
                "Pure joy in every pixel âœ¨ðŸŒˆ",
                "Smiles as bright as the day ðŸŒŸðŸ˜Š",
                "Happiness overload ðŸ’•ðŸŒ¸"
            ],
            "emojis": ["ðŸ˜Š", "âœ¨", "ðŸŒˆ", "ðŸ’›", "ðŸŒ¸", "ðŸŒŸ"]
        },
        "sad": {
            "templates": [
                "Quiet moments in a noisy world ðŸŒ§ï¸ðŸ’™",
                "Raindrops match my mood ðŸŒ§ï¸ðŸŒ¿",
                "Soft shades of a heavy heart ðŸ’­ðŸ’”",
                "Sometimes beauty is in the melancholy ðŸŒ™ðŸ’§"
            ],
            "emojis": ["ðŸ’™", "ðŸŒ§ï¸", "ðŸŒ™", "ðŸ’§", "ðŸ’­", "ðŸ‚"]
        },
        "adventurous": {
            "templates": [
                "Chasing horizons ðŸŒâœ¨",
                "Adventure is calling, I must go ðŸžï¸ðŸš€",
                "Collecting moments, not things ðŸ“ðŸŒ„",
                "Lost in the right direction ðŸ§­ðŸŒ¿"
            ],
            "emojis": ["ðŸŒ", "ðŸžï¸", "ðŸš€", "ðŸŒ„", "ðŸ§­", "ðŸŒ¿"]
        },
        "romantic": {
            "templates": [
                "Love written in the skies ðŸŒ¹ðŸ’«",
                "Two souls, one heartbeat â¤ï¸ðŸŒ™",
                "Whispers of forever ðŸ’•ðŸŒ¸",
                "In your arms is home ðŸŒ¹ðŸ’"
            ],
            "emojis": ["ðŸŒ¹", "ðŸ’«", "â¤ï¸", "ðŸŒ™", "ðŸ’•", "ðŸ’"]
        },
        "mysterious": {
            "templates": [
                "Whispers in the shadows ðŸŒŒðŸ–¤",
                "Stories the moon will never tell ðŸŒ™âœ¨",
                "Lost between reality and dreams ðŸŒ«ï¸ðŸ”®",
                "Eyes full of secrets ðŸ–¤ðŸŒ‘"
            ],
            "emojis": ["ðŸŒŒ", "ðŸ–¤", "ðŸŒ™", "âœ¨", "ðŸ”®", "ðŸŒ‘"]
        },
        "energetic": {
            "templates": [
                "Vibes louder than my playlist ðŸŽ¶ðŸ”¥",
                "Too much energy to stand still âš¡ðŸ’¥",
                "Life in full volume ðŸŽ§âœ¨",
                "Powered by pure adrenaline ðŸš€ðŸ”¥"
            ],
            "emojis": ["âš¡", "ðŸ”¥", "ðŸ’¥", "ðŸŽ§", "âœ¨", "ðŸš€"]
        }
    }

    vibe_data = vibe_styles.get(vibe, vibe_styles["happy"])

    # Shorten base caption and extract keywords
    base_caption_clean = base_caption.strip().capitalize()
    keywords = base_caption_clean.split()[:5]  # top 5 words

    # Creative rephrasings using keywords
    keyword_phrase = " ".join(keywords)
    custom_templates = [
        f"{keyword_phrase} vibes {random.choice(vibe_data['emojis'])}",
        f"{random.choice(vibe_data['templates'])} â€” {keyword_phrase.lower()}",
        f"{keyword_phrase} but make it {vibe} {random.choice(vibe_data['emojis'])}",
        f"Just {keyword_phrase.lower()} things {random.choice(vibe_data['emojis'])}"
    ]

    # Merge templates
    all_templates = vibe_data["templates"] + custom_templates

    # If user provided extra description, weave it in
    if user_description:
        all_templates += [
            f"{random.choice(vibe_data['templates'])} â€¢ {user_description.lower()}",
            f"{user_description.capitalize()} & {keyword_phrase.lower()} {random.choice(vibe_data['emojis'])}"
        ]

    # Pick a stylish caption
    caption = random.choice(all_templates)

    return caption.strip()



def generate_enhanced_caption(image, vibe: str, user_description: str = ""):
    """Generate captions using ViT-GPT2 and style them."""
    image = process_image(image)
    pixel_values = processor(images=image, return_tensors="pt").pixel_values.to(device)

    with torch.no_grad():
        output_ids = model.generate(
            pixel_values,
            max_length=50,
            min_length=15,
            num_beams=5,
            temperature=0.8,
            repetition_penalty=1.2
        )
    base_caption = tokenizer.decode(output_ids[0], skip_special_tokens=True).strip()

    enhanced_caption = enhance_caption_with_style(base_caption, vibe, user_description)
    return enhanced_caption, base_caption


def process_image(image):
    """Ensure image is RGB and resized."""
    if image.mode != 'RGB':
        image = image.convert('RGB')
    max_size = 512
    if max(image.size) > max_size:
        image.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)
    return image

# ================================
# Cell 5: API endpoints
# ================================
class CaptionURLRequest(BaseModel):
    image_url: str
    vibe: str = "happy"
    user_description: str = ""

class RefreshCaptionRequest(BaseModel):
    base_caption: str
    vibe: str = "happy"
    user_description: str = ""

@app.post("/generate-caption-upload")
async def generate_caption_upload(
    file: UploadFile = File(...),
    vibe: str = Form("happy"),
    user_description: str = Form("")
):
    try:
        if not file.content_type.startswith('image/'):
            raise HTTPException(status_code=400, detail="File must be an image")

        contents = await file.read()
        image = Image.open(io.BytesIO(contents))

        cool_caption, base_caption = generate_enhanced_caption(image, vibe.lower(), user_description)

        return {
            "success": True,
            "caption": cool_caption,
            "base_caption": base_caption,
            "user_description": user_description,
            "vibe": vibe
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error generating caption: {str(e)}")


@app.post("/generate-caption-url")
async def generate_caption_url(body: CaptionURLRequest):
    try:
        response = requests.get(body.image_url, timeout=10)
        response.raise_for_status()
        image = Image.open(io.BytesIO(response.content))

        cool_caption, base_caption = generate_enhanced_caption(image, body.vibe.lower(), body.user_description)

        return {
            "success": True,
            "caption": cool_caption,
            "base_caption": base_caption,
            "user_description": body.user_description,
            "vibe": body.vibe
        }
    except requests.RequestException:
        raise HTTPException(status_code=400, detail="Could not download image from URL")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error generating caption: {str(e)}")


@app.post("/refresh-caption")
async def refresh_caption(body: RefreshCaptionRequest):
    try:
        cool_caption = enhance_caption_with_style(body.base_caption, body.vibe.lower(), body.user_description)
        return {
            "success": True,
            "caption": cool_caption,
            "base_caption": body.base_caption,
            "user_description": body.user_description,
            "vibe": body.vibe
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error refreshing caption: {str(e)}")


@app.get("/vibes")
async def get_available_vibes():
    return {
        "vibes": ["happy", "sad", "adventurous", "romantic", "mysterious", "energetic"]
    }

import nest_asyncio
import uvicorn

ngrok.set_auth_token("31AlJuXfCHs6opLvtXrEfp45qgE_5ddxVm5BMpRntk5Qf7eVJ")
public_url = ngrok.connect(8000)
print(f"ðŸš€ Your API is now accessible at: {public_url}")
print(f"ðŸ“‹ Copy this URL for your frontend: {public_url}")

# Allow nested event loops/
nest_asyncio.apply()

# Run server directly
uvicorn.run(app, host="0.0.0.0", port=8000)

